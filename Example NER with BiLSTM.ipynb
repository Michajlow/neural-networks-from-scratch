{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The next notebook shows an example script for simple solution of Named Entity Recognition task with BiLSTM without any feature engineering and advanced techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import sys\n",
    "import re\n",
    "import pandas as pd #we will need it a bit just to easily handle data from .csv file\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence #</th>\n",
       "      <th>Word</th>\n",
       "      <th>POS</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>Thousands</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>of</td>\n",
       "      <td>IN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>demonstrators</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>have</td>\n",
       "      <td>VBP</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>marched</td>\n",
       "      <td>VBN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Sentence #           Word  POS Tag\n",
       "0  Sentence: 1      Thousands  NNS   O\n",
       "1          NaN             of   IN   O\n",
       "2          NaN  demonstrators  NNS   O\n",
       "3          NaN           have  VBP   O\n",
       "4          NaN        marched  VBN   O"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The annotatied corpus I've took from here\n",
    "# https://www.kaggle.com/abhinavwalia95/entity-annotated-corpus\n",
    "\n",
    "# Lets see what is there\n",
    "source = pd.read_csv('testdata/ner_dataset.csv', encoding = 'latin1', sep=',')\n",
    "source.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amount of initial sentences 47959\n",
      "Max sentence length-  104\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIEmNMgAkqVEGgCQ1ygCQpEYZAJLUqP8HhGaI0e98Ms4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ffa43b647f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "source['Word'] = source['Word'].str.lower() #Lets make all words lowercase. \n",
    "                                            # Basically its doubtable approach in this case: we \n",
    "                                            # reduce dimensiality (less unique words) but skip difference \n",
    "                                            # between of some words (like us (pronoun) and US (geo location))\n",
    "                                            # so its subject for experiments then common approach\n",
    "                \n",
    "# Lets find all indeces the every new sentence starts                \n",
    "sents_indeces = source[pd.notnull(source['Sentence #'])].index\n",
    "sents_number = len(sents_indeces)\n",
    "print('Amount of initial sentences', sents_number)\n",
    "\n",
    "# and this trick gives sentences length distribution\n",
    "diff = np.diff(sents_indeces)\n",
    "\n",
    "# to future calculations we need to make all sequences length equal. One of the approach to pad all sentences\n",
    "# to the max lenght in the corpus. If the corpus is big enough you can just choose length which will cover \n",
    "# 99% of cases (in current distribution such length is 60)\n",
    "maxlen = max(diff)\n",
    "print('Max sentence length- ', maxlen)\n",
    "\n",
    "# Lets watch on it\n",
    "plt.hist(diff, bins=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amount of sentences for train 40765\n",
      "Amount of sentences for test 7194\n"
     ]
    }
   ],
   "source": [
    "# Split words and tags on sentences\n",
    "all_sentences = np.array([np.split(source.Word.values, sents_indeces[1:]),\n",
    "                          np.split(source.Tag.values, sents_indeces[1:])])\n",
    "\n",
    "# then just mix sentences and take 85% for training and 15% for test\n",
    "index = np.random.permutation(range(sents_number))\n",
    "\n",
    "train_sentences = all_sentences[:,index[:int(0.85*sents_number)]]\n",
    "train_sentences_idx = np.cumsum([len(sent) for sent in train_sentences[1,:]])\n",
    "\n",
    "test_sentences = all_sentences[:,index[int(0.85*sents_number):]]\n",
    "test_sentences_idx = np.cumsum([len(sent) for sent in test_sentences[1,:]])\n",
    "\n",
    "print('Amount of sentences for train', train_sentences.shape[1])\n",
    "print('Amount of sentences for test', test_sentences.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;16;48;5;231mB-tim                    17295\n",
      "\u001b[38;5;16;48;5;231mB-org                    17001\n",
      "\u001b[38;5;16;48;5;231mI-tim                     5486\n",
      "\u001b[38;5;16;48;5;231mI-geo                     6290\n",
      "\u001b[38;5;16;48;5;231mI-org                    14216\n",
      "\u001b[38;5;16;48;5;231mB-geo                    32090\n",
      "\u001b[38;5;16;48;5;217mI-gpe                      169\n",
      "\u001b[38;5;16;48;5;217mB-eve                      258\n",
      "\u001b[38;5;16;48;5;217mI-art                      248\n",
      "\u001b[38;5;16;48;5;231mB-gpe                    13450\n",
      "\u001b[38;5;16;48;5;217mI-eve                      210\n",
      "\u001b[38;5;16;48;5;217mB-art                      338\n",
      "\u001b[38;5;16;48;5;217mB-nat                      173\n",
      "\u001b[38;5;16;48;5;231mO                       754834\n",
      "\u001b[38;5;16;48;5;231mB-per                    14504\n",
      "\u001b[38;5;16;48;5;217mI-nat                       44\n",
      "\u001b[38;5;16;48;5;231mI-per                    14666\n"
     ]
    }
   ],
   "source": [
    "# For the next few steps we need unroll sentences again to the list of tokens, but only train sentences \n",
    "train_tags = np.concatenate(train_sentences[1,:])\n",
    "train_tokens = np.concatenate(train_sentences[0,:])\n",
    "\n",
    "# Lets see the tag distribution over the train corpus \n",
    "train_tags_counts = Counter(train_tags)\n",
    "for k,i in train_tags_counts.items():\n",
    "    if i<1000: c = '217' # highlight tags which have less then 1000 examples in train courpus\n",
    "    else: c = '231'\n",
    "    print('\\033[38;5;16;48;5;{}m{:15}{:15}'.format(c,k,i)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amount of words be changed to Unk 620\n"
     ]
    }
   ],
   "source": [
    "# We see how our problem is unbalanced. The difference between \"O\" and \"I-nat\" for example is enermous and it\n",
    "# will bring consequances we meet on the next stemps.\n",
    "\n",
    "# Lets make our solution a bit closer to real life problem. Some words might be unknown for the model after\n",
    "# train, so we choose randomly a small amount of words which appeared only once in corpus and changed them to be\n",
    "# \"Unknown\" letting the model to train on cases, where unknown word can appear \n",
    "\n",
    "words2Unk = np.random.permutation([k for k,i in Counter(train_tokens).items() if i==1])\n",
    "words2Unk = words2Unk[:int(len(words2Unk)*0.05)]\n",
    "print('Amount of words be changed to Unk', len(words2Unk))\n",
    "\n",
    "idx2Unk = np.ravel([np.where(train_tokens==w) for w in words2Unk])\n",
    "train_tokens[idx2Unk] = 'Unk'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unique tokens (vocabluary size) - (29169,)\n",
      "unique tags (output features) - (17,)\n"
     ]
    }
   ],
   "source": [
    "# Then build dictionaries which to convert our tokens and tags to indeces and vice-versa\n",
    "# doing it on train corpus only\n",
    "\n",
    "u_tokens = np.unique(train_tokens)\n",
    "u_tags = np.unique(train_tags)\n",
    "\n",
    "print('unique tokens (vocabluary size) -', u_tokens.shape)\n",
    "print('unique tags (output features) -', u_tags.shape)\n",
    "\n",
    "token2indices = dict((c, i) for i, c in enumerate(u_tokens))\n",
    "indices2tokens = dict((i, c) for i, c in enumerate(u_tokens))\n",
    "\n",
    "token2indices['<pad>'] = len(u_tokens)\n",
    "indices2tokens[len(u_tokens)] = '<pad>'\n",
    "\n",
    "tags2indices = dict((c, i) for i, c in enumerate(u_tags))\n",
    "indices2tags = dict((i, c) for i, c in enumerate(u_tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# convert train tokens to indeces\n",
    "\n",
    "train_tokens_num = np.array([token2indices[w] for w in train_tokens])\n",
    "train_tags_num = np.array([tags2indices[w] for w in train_tags])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# convert test tokens to indeces\n",
    "\n",
    "# additional function is required, cos probably some unknown words could be met in test corpus (like in real \n",
    "# live)\n",
    "def get_index(w, d):\n",
    "    if w in d:\n",
    "        return d[w]\n",
    "    else:\n",
    "        return d['Unk']\n",
    "    \n",
    "test_tokens_num = np.array([get_index(w, token2indices) for w in np.concatenate(test_sentences[0,:])])\n",
    "test_tags_num = np.array([get_index(w, tags2indices) for w in np.concatenate(test_sentences[1,:])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# then split converted tokens and tags to sentences again and pad them\n",
    "\n",
    "def num_pad(array, m, _dict, k):\n",
    "    l = len(array)\n",
    "    return np.pad(array, [0,m-l], 'constant', constant_values=( _dict[k]))\n",
    "\n",
    "train_tokens_num_sents = [num_pad(s, maxlen, token2indices, '<pad>')  for s \n",
    "                          in np.split(train_tokens_num, train_sentences_idx)]\n",
    "train_tags_num_sents = [num_pad(s, maxlen, tags2indices, 'O') for s \n",
    "                        in np.split(train_tags_num, train_sentences_idx)]\n",
    "\n",
    "test_tokens_num_sents = [num_pad(s, maxlen, token2indices, '<pad>')  for s \n",
    "                          in np.split(test_tokens_num, test_sentences_idx)]\n",
    "test_tags_num_sents = [num_pad(s, maxlen, tags2indices, 'O') for s \n",
    "                        in np.split(test_tags_num, test_sentences_idx)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes of train inputs x = (1, 40766, 104), y = (17, 40766, 104)\n"
     ]
    }
   ],
   "source": [
    "# prepare train and test examples to the shape our LSTM NN requires:\n",
    "# (num of features, batch size, timesteps)\n",
    "# As the word feature we pass the index of word in vocabluary and let embedding layer to find the best\n",
    "# representation vector for this task\n",
    "\n",
    "x_train = np.array(train_tokens_num_sents)\n",
    "x_train = x_train.reshape(1, x_train.shape[0], x_train.shape[1])\n",
    "y_train_indeces = np.array(train_tags_num_sents).T\n",
    "y_train = np.eye(u_tags.shape[0]).astype(np.uint8)[y_train_indeces].T\n",
    "print('Shapes of train inputs x = {}, y = {}'.format(x_train.shape, y_train.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes of train inputs x = (1, 7195, 104), y = (1, 7195, 104)\n"
     ]
    }
   ],
   "source": [
    "x_test = np.array(test_tokens_num_sents)\n",
    "x_test = x_test.reshape(1, x_test.shape[0], x_test.shape[1])\n",
    "y_test_indeces = np.array(test_tags_num_sents).T\n",
    "y_test = np.eye(u_tags.shape[0]).astype(np.uint8)[y_test_indeces].T\n",
    "print('Shapes of train inputs x = {}, y = {}'.format(x_test.shape, x_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;15;48;5;232mTrain tokens                  Train tags     Test tokens                   Test tags      \n",
      "\u001b[38;5;16;48;5;230min                            O              \u001b[38;5;16;48;5;194min                            O              \n",
      "\u001b[38;5;16;48;5;230ma                             O              \u001b[38;5;16;48;5;194mmay                           B-tim          \n",
      "\u001b[38;5;16;48;5;230mseparate                      O              \u001b[38;5;16;48;5;194m,                             O              \n",
      "\u001b[38;5;16;48;5;230mdevelopment                   O              \u001b[38;5;16;48;5;194ma                             O              \n",
      "\u001b[38;5;16;48;5;230m,                             O              \u001b[38;5;16;48;5;194mmoscow                        B-geo          \n",
      "\u001b[38;5;16;48;5;230mattorneys                     O              \u001b[38;5;16;48;5;194mcourt                         O              \n",
      "\u001b[38;5;16;48;5;230mfor                           O              \u001b[38;5;16;48;5;194msentenced                     O              \n",
      "\u001b[38;5;16;48;5;230mousted                        O              \u001b[38;5;16;48;5;194mthe                           O              \n",
      "\u001b[38;5;16;48;5;230mleader                        O              \u001b[38;5;16;48;5;194mtwo                           O              \n",
      "\u001b[38;5;16;48;5;230msaddam                        B-per          \u001b[38;5;16;48;5;194mmen                           O              \n",
      "\u001b[38;5;16;48;5;230mhussein                       I-per          \u001b[38;5;16;48;5;194mto                            O              \n",
      "\u001b[38;5;16;48;5;230msay                           O              \u001b[38;5;16;48;5;194mnine                          O              \n",
      "\u001b[38;5;16;48;5;230mhe                            O              \u001b[38;5;16;48;5;194myears                         O              \n",
      "\u001b[38;5;16;48;5;230mmet                           O              \u001b[38;5;16;48;5;194min                            O              \n",
      "\u001b[38;5;16;48;5;230mthursday                      B-tim          \u001b[38;5;16;48;5;194mprison                        O              \n",
      "\u001b[38;5;16;48;5;230m,                             O              \u001b[38;5;16;48;5;194mon                            O              \n",
      "\u001b[38;5;16;48;5;230mfor                           O              \u001b[38;5;16;48;5;194mfraud                         O              \n",
      "\u001b[38;5;16;48;5;230mthe                           O              \u001b[38;5;16;48;5;194mand                           O              \n",
      "\u001b[38;5;16;48;5;230mfirst                         O              \u001b[38;5;16;48;5;194mtax                           O              \n",
      "\u001b[38;5;16;48;5;230mtime                          O              \u001b[38;5;16;48;5;194mevasion                       O              \n",
      "\u001b[38;5;16;48;5;230msince                         O              \u001b[38;5;16;48;5;194mcharges                       O              \n",
      "\u001b[38;5;16;48;5;230mhis                           O              \u001b[38;5;16;48;5;194m.                             O              \n",
      "\u001b[38;5;16;48;5;230mcapture                       O              \u001b[38;5;16;48;5;194m<pad>                         O              \n",
      "\u001b[38;5;16;48;5;230mlast                          O              \u001b[38;5;16;48;5;194m<pad>                         O              \n",
      "\u001b[38;5;16;48;5;230myear                          O              \u001b[38;5;16;48;5;194m<pad>                         O              \n"
     ]
    }
   ],
   "source": [
    "# We deed a lot of manipulations with tokens, tags and indeces and it could be a good approach to check\n",
    "# what actually we have got before training\n",
    "idx = np.random.choice(range(x_test.shape[1]))\n",
    "seq_len = 25\n",
    "print('\\033[38;5;15;48;5;232m{:30}{:15}{:30}{:15}'.format('Train tokens', 'Train tags', \n",
    "                                                          'Test tokens', 'Test tags'))\n",
    "for el in zip([indices2tokens[w] for w in x_train[0,idx,:seq_len]], \n",
    "              [indices2tags[w] for w in np.argmax(y_train[:,idx,:seq_len], axis=0)],\n",
    "              [indices2tokens[w] for w in x_test[0,idx,:seq_len]], \n",
    "              [indices2tags[w] for w in np.argmax(y_test[:,idx,:seq_len], axis=0)]):\n",
    "    print('\\033[38;5;16;48;5;230m{:30}{:15}\\033[38;5;16;48;5;194m{:30}{:15}'.format(el[0], el[1], \n",
    "                                                                                    el[2], el[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17, 748280)\n"
     ]
    }
   ],
   "source": [
    "# Looks fine!\n",
    "\n",
    "# The only last preprocesssing is reshape tags of test examples to check our model \n",
    "# in efficient way\n",
    "\n",
    "sh = y_test.shape\n",
    "_y_test = y_test.reshape(sh[0], sh[1]*sh[2])\n",
    "print(_y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# the next function will be executed every n epoch to show how the training is going and \n",
    "# estimate the model\n",
    "\n",
    "\n",
    "def on_epoch_end(*args):\n",
    "    if args[1] % 1 == 0:\n",
    "        print()\n",
    "        print(\"Cost after epoch %i: %f\" %(args[1], args[2]))\n",
    "        num_outputs = len(u_tags)\n",
    "        _y_pred = np.around(args[0].predict(x_test))\n",
    "        _y_pred = _y_pred.reshape(sh[0], sh[1]*sh[2])\n",
    "        s = np.argmax(_y_pred[:,:], axis=0)\n",
    "        r = np.argmax(_y_test[:,:], axis=0)\n",
    "        gacc = np.sum(r==s)/_y_test.shape[1]\n",
    "        print('General accurancy', gacc, '\\n')\n",
    "\n",
    "        header = '\\033[38;5;15;48;5;232m{:15}{:15}{:15}{:15}{:15}'\n",
    "        line = '\\033[38;5;16;48;5;{}m{:15}{:10.8f}{:15.8f}{:15.8f}{:15}'\n",
    "        print(header.format('Tag','Precision','Recall','F1','Train tags'))\n",
    "\n",
    "        accurancy = np.empty(num_outputs)\n",
    "        precision = np.empty(num_outputs)\n",
    "        recall = np.empty(num_outputs)\n",
    "        f1 = np.empty(num_outputs)\n",
    "        for num, name in indices2tags.items():\n",
    "            selected = _y_pred[num,:]==1\n",
    "            relevant = _y_test[num,:]==1\n",
    "            tp = np.count_nonzero(selected*relevant)\n",
    "            fp = np.count_nonzero(selected*(relevant-1))\n",
    "            fn = np.count_nonzero((selected-1)*relevant)\n",
    "            accurancy[num] = tp/np.count_nonzero(relevant)\n",
    "            if accurancy[num] == 0:\n",
    "                precision[num], recall[num], f1[num] = [0,0,0]\n",
    "            else:\n",
    "                precision[num] = (tp / (tp + fp))\n",
    "                recall[num] = (tp / (tp + fn))\n",
    "                f1[num] = 2*((precision[num] * recall[num])/(precision[num] + recall[num]))\n",
    "            if f1[num]<0.6: c = '217' #highlight less then 0.6 f1 rate\n",
    "            else: c = '231'\n",
    "            print(line.format(c, name, precision[num], recall[num], f1[num], train_tags_counts[name]))\n",
    "        print('\\033[38;5;16;48;5;231m')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from mylab.layers import layer, lstm_layer, rnn_layer, embedding_layer, brnn\n",
    "import numpy as np\n",
    "from mylab import nnet\n",
    "from mylab.utils import define_minibatches, progress, tanh, softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "model = nnet()\n",
    "model.add(embedding_layer(64, len(token2indices))) # embedding layer takes number of hidden \n",
    "                                                   # units and vocabluary\n",
    "                                                   # size\n",
    "model.add(brnn(lstm_layer(32))) # add LSTM layer inside BRNN wrapper, \n",
    "                                # hidden units = 32 (activation function is tanh by default)\n",
    "model.add(layer(17, softmax))   # activation function - softmax\n",
    "model.report_function = on_epoch_end # add report function we specified before "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensional checking...\n",
      "\n",
      "input shape - (1, 40766, 104)\n",
      "\n",
      "layer 0 output shape -  (64, 40766, 104)\n",
      "layer 1 output shape -  (64, 40766, 104)\n",
      "layer 2 output shape -  (17, 40766, 104)\n",
      "Parameters are initialized\n",
      "\n",
      "epoch 0 -[============================================================] 100.0% ...0.07744082775099649\n",
      "Cost after epoch 0: 0.077441\n",
      "General accurancy 0.9874071203292885 \n",
      "\n",
      "\u001b[38;5;15;48;5;232mTag            Precision      Recall         F1             Train tags     \n",
      "\u001b[38;5;16;48;5;217mB-art          0.00000000     0.00000000     0.00000000            338\n",
      "\u001b[38;5;16;48;5;217mB-eve          0.00000000     0.00000000     0.00000000            258\n",
      "\u001b[38;5;16;48;5;231mB-geo          0.85485446     0.78790061     0.82001312          32090\n",
      "\u001b[38;5;16;48;5;231mB-gpe          0.94718910     0.91900826     0.93288591          13450\n",
      "\u001b[38;5;16;48;5;217mB-nat          0.00000000     0.00000000     0.00000000            173\n",
      "\u001b[38;5;16;48;5;231mB-org          0.80775194     0.49745385     0.61571794          17001\n",
      "\u001b[38;5;16;48;5;231mB-per          0.82448790     0.71238938     0.76435045          14504\n",
      "\u001b[38;5;16;48;5;231mB-tim          0.88607155     0.83969717     0.86226128          17295\n",
      "\u001b[38;5;16;48;5;217mI-art          0.00000000     0.00000000     0.00000000            248\n",
      "\u001b[38;5;16;48;5;217mI-eve          0.00000000     0.00000000     0.00000000            210\n",
      "\u001b[38;5;16;48;5;231mI-geo          0.80501393     0.51423488     0.62757872           6290\n",
      "\u001b[38;5;16;48;5;217mI-gpe          0.00000000     0.00000000     0.00000000            169\n",
      "\u001b[38;5;16;48;5;217mI-nat          0.00000000     0.00000000     0.00000000             44\n",
      "\u001b[38;5;16;48;5;217mI-org          0.75271318     0.37811526     0.50336962          14216\n",
      "\u001b[38;5;16;48;5;231mI-per          0.81676892     0.77253385     0.79403579          14666\n",
      "\u001b[38;5;16;48;5;231mI-tim          0.88429752     0.51343570     0.64966606           5486\n",
      "\u001b[38;5;16;48;5;231mO              0.99663865     0.99754437     0.99709131         754834\n",
      "\u001b[38;5;16;48;5;231m\n",
      "epoch 1 -[============================================================] 100.0% ...0.027758697143594458\n",
      "Cost after epoch 1: 0.027759\n",
      "General accurancy 0.9895801037044957 \n",
      "\n",
      "\u001b[38;5;15;48;5;232mTag            Precision      Recall         F1             Train tags     \n",
      "\u001b[38;5;16;48;5;217mB-art          0.00000000     0.00000000     0.00000000            338\n",
      "\u001b[38;5;16;48;5;217mB-eve          0.00000000     0.00000000     0.00000000            258\n",
      "\u001b[38;5;16;48;5;231mB-geo          0.85753778     0.83777458     0.84754098          32090\n",
      "\u001b[38;5;16;48;5;231mB-gpe          0.95075758     0.93347107     0.94203503          13450\n",
      "\u001b[38;5;16;48;5;217mB-nat          0.00000000     0.00000000     0.00000000            173\n",
      "\u001b[38;5;16;48;5;231mB-org          0.83431953     0.53851050     0.65454545          17001\n",
      "\u001b[38;5;16;48;5;231mB-per          0.84015852     0.76749799     0.80218625          14504\n",
      "\u001b[38;5;16;48;5;231mB-tim          0.90673759     0.84167215     0.87299420          17295\n",
      "\u001b[38;5;16;48;5;217mI-art          0.00000000     0.00000000     0.00000000            248\n",
      "\u001b[38;5;16;48;5;217mI-eve          0.00000000     0.00000000     0.00000000            210\n",
      "\u001b[38;5;16;48;5;231mI-geo          0.82663317     0.58540925     0.68541667           6290\n",
      "\u001b[38;5;16;48;5;217mI-gpe          0.00000000     0.00000000     0.00000000            169\n",
      "\u001b[38;5;16;48;5;217mI-nat          0.00000000     0.00000000     0.00000000             44\n",
      "\u001b[38;5;16;48;5;217mI-org          0.78367618     0.45989097     0.57963190          14216\n",
      "\u001b[38;5;16;48;5;231mI-per          0.85327869     0.80541586     0.82865672          14666\n",
      "\u001b[38;5;16;48;5;231mI-tim          0.90269461     0.57869482     0.70526316           5486\n",
      "\u001b[38;5;16;48;5;231mO              0.99628707     0.99838133     0.99733310         754834\n",
      "\u001b[38;5;16;48;5;231m\n",
      "epoch 2 -[============================================================] 100.0% ...0.022442464137136197\n",
      "Cost after epoch 2: 0.022442\n",
      "General accurancy 0.9900692254236382 \n",
      "\n",
      "\u001b[38;5;15;48;5;232mTag            Precision      Recall         F1             Train tags     \n",
      "\u001b[38;5;16;48;5;217mB-art          0.00000000     0.00000000     0.00000000            338\n",
      "\u001b[38;5;16;48;5;217mB-eve          1.00000000     0.18000000     0.30508475            258\n",
      "\u001b[38;5;16;48;5;231mB-geo          0.85884074     0.84569680     0.85221809          32090\n",
      "\u001b[38;5;16;48;5;231mB-gpe          0.95854701     0.92685950     0.94243697          13450\n",
      "\u001b[38;5;16;48;5;217mB-nat          1.00000000     0.17857143     0.30303030            173\n",
      "\u001b[38;5;16;48;5;231mB-org          0.80977778     0.57988542     0.67581602          17001\n",
      "\u001b[38;5;16;48;5;231mB-per          0.81443299     0.79444891     0.80431684          14504\n",
      "\u001b[38;5;16;48;5;231mB-tim          0.90630442     0.85648453     0.88069047          17295\n",
      "\u001b[38;5;16;48;5;217mI-art          0.00000000     0.00000000     0.00000000            248\n",
      "\u001b[38;5;16;48;5;217mI-eve          0.00000000     0.00000000     0.00000000            210\n",
      "\u001b[38;5;16;48;5;231mI-geo          0.82260024     0.60231317     0.69542886           6290\n",
      "\u001b[38;5;16;48;5;217mI-gpe          1.00000000     0.27586207     0.43243243            169\n",
      "\u001b[38;5;16;48;5;217mI-nat          0.00000000     0.00000000     0.00000000             44\n",
      "\u001b[38;5;16;48;5;231mI-org          0.74762171     0.52024922     0.61354765          14216\n",
      "\u001b[38;5;16;48;5;231mI-per          0.85505481     0.81470019     0.83438986          14666\n",
      "\u001b[38;5;16;48;5;231mI-tim          0.86762779     0.63531670     0.73351801           5486\n",
      "\u001b[38;5;16;48;5;231mO              0.99683168     0.99812582     0.99747833         754834\n",
      "\u001b[38;5;16;48;5;231m\n",
      "epoch 3 -[============================================================] 100.0% ...0.019387139104844364\n",
      "Cost after epoch 3: 0.019387\n",
      "General accurancy 0.9902977495055327 \n",
      "\n",
      "\u001b[38;5;15;48;5;232mTag            Precision      Recall         F1             Train tags     \n",
      "\u001b[38;5;16;48;5;217mB-art          0.00000000     0.00000000     0.00000000            338\n",
      "\u001b[38;5;16;48;5;217mB-eve          0.90000000     0.18000000     0.30000000            258\n",
      "\u001b[38;5;16;48;5;231mB-geo          0.87281936     0.83777458     0.85493799          32090\n",
      "\u001b[38;5;16;48;5;231mB-gpe          0.96181896     0.92644628     0.94380130          13450\n",
      "\u001b[38;5;16;48;5;217mB-nat          1.00000000     0.14285714     0.25000000            173\n",
      "\u001b[38;5;16;48;5;231mB-org          0.77737810     0.61903246     0.68922750          17001\n",
      "\u001b[38;5;16;48;5;231mB-per          0.79612035     0.80893001     0.80247406          14504\n",
      "\u001b[38;5;16;48;5;231mB-tim          0.90491010     0.86142199     0.88263069          17295\n",
      "\u001b[38;5;16;48;5;217mI-art          0.00000000     0.00000000     0.00000000            248\n",
      "\u001b[38;5;16;48;5;217mI-eve          0.00000000     0.00000000     0.00000000            210\n",
      "\u001b[38;5;16;48;5;231mI-geo          0.81727575     0.65658363     0.72816971           6290\n",
      "\u001b[38;5;16;48;5;217mI-gpe          1.00000000     0.37931034     0.55000000            169\n",
      "\u001b[38;5;16;48;5;217mI-nat          0.00000000     0.00000000     0.00000000             44\n",
      "\u001b[38;5;16;48;5;231mI-org          0.73119358     0.56775701     0.63919334          14216\n",
      "\u001b[38;5;16;48;5;231mI-per          0.84775641     0.81856867     0.83290691          14666\n",
      "\u001b[38;5;16;48;5;231mI-tim          0.82643678     0.69001919     0.75209205           5486\n",
      "\u001b[38;5;16;48;5;231mO              0.99710729     0.99783717     0.99747210         754834\n",
      "\u001b[38;5;16;48;5;231m\n",
      "epoch 4 -[============================================================] 100.0% ...0.017179854357982683\n",
      "Cost after epoch 4: 0.017180\n",
      "General accurancy 0.9903832789864756 \n",
      "\n",
      "\u001b[38;5;15;48;5;232mTag            Precision      Recall         F1             Train tags     \n",
      "\u001b[38;5;16;48;5;217mB-art          0.50000000     0.01562500     0.03030303            338\n",
      "\u001b[38;5;16;48;5;217mB-eve          0.65000000     0.26000000     0.37142857            258\n",
      "\u001b[38;5;16;48;5;231mB-geo          0.84442116     0.87072380     0.85737080          32090\n",
      "\u001b[38;5;16;48;5;231mB-gpe          0.96827466     0.92066116     0.94386782          13450\n",
      "\u001b[38;5;16;48;5;217mB-nat          0.83333333     0.17857143     0.29411765            173\n",
      "\u001b[38;5;16;48;5;231mB-org          0.79674099     0.59134309     0.67884545          17001\n",
      "\u001b[38;5;16;48;5;231mB-per          0.85349716     0.72646822     0.78487614          14504\n",
      "\u001b[38;5;16;48;5;231mB-tim          0.89754935     0.86800527     0.88253012          17295\n",
      "\u001b[38;5;16;48;5;217mI-art          0.00000000     0.00000000     0.00000000            248\n",
      "\u001b[38;5;16;48;5;217mI-eve          0.36363636     0.09302326     0.14814815            210\n",
      "\u001b[38;5;16;48;5;231mI-geo          0.78433367     0.68594306     0.73184623           6290\n",
      "\u001b[38;5;16;48;5;217mI-gpe          1.00000000     0.37931034     0.55000000            169\n",
      "\u001b[38;5;16;48;5;217mI-nat          0.00000000     0.00000000     0.00000000             44\n",
      "\u001b[38;5;16;48;5;231mI-org          0.73164557     0.56269470     0.63614352          14216\n",
      "\u001b[38;5;16;48;5;231mI-per          0.86127660     0.78297872     0.82026342          14666\n",
      "\u001b[38;5;16;48;5;231mI-tim          0.85994764     0.63051823     0.72757475           5486\n",
      "\u001b[38;5;16;48;5;231mO              0.99663274     0.99823907     0.99743526         754834\n",
      "\u001b[38;5;16;48;5;231m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5 -[============================================================] 100.0% ...0.015384344708649782\n",
      "Cost after epoch 5: 0.015384\n",
      "General accurancy 0.9901280269417865 \n",
      "\n",
      "\u001b[38;5;15;48;5;232mTag            Precision      Recall         F1             Train tags     \n",
      "\u001b[38;5;16;48;5;217mB-art          0.66666667     0.12500000     0.21052632            338\n",
      "\u001b[38;5;16;48;5;217mB-eve          0.85714286     0.24000000     0.37500000            258\n",
      "\u001b[38;5;16;48;5;231mB-geo          0.84878311     0.85397911     0.85137318          32090\n",
      "\u001b[38;5;16;48;5;231mB-gpe          0.96111111     0.92933884     0.94495798          13450\n",
      "\u001b[38;5;16;48;5;217mB-nat          0.87500000     0.25000000     0.38888889            173\n",
      "\u001b[38;5;16;48;5;231mB-org          0.72967112     0.64258434     0.68336436          17001\n",
      "\u001b[38;5;16;48;5;231mB-per          0.82686437     0.76267096     0.79347144          14504\n",
      "\u001b[38;5;16;48;5;231mB-tim          0.90409075     0.86570112     0.88447957          17295\n",
      "\u001b[38;5;16;48;5;217mI-art          0.00000000     0.00000000     0.00000000            248\n",
      "\u001b[38;5;16;48;5;217mI-eve          0.50000000     0.06976744     0.12244898            210\n",
      "\u001b[38;5;16;48;5;231mI-geo          0.76047904     0.67793594     0.71683913           6290\n",
      "\u001b[38;5;16;48;5;231mI-gpe          1.00000000     0.44827586     0.61904762            169\n",
      "\u001b[38;5;16;48;5;217mI-nat          0.00000000     0.00000000     0.00000000             44\n",
      "\u001b[38;5;16;48;5;231mI-org          0.70833333     0.55607477     0.62303665          14216\n",
      "\u001b[38;5;16;48;5;231mI-per          0.86599297     0.76247582     0.81094425          14666\n",
      "\u001b[38;5;16;48;5;231mI-tim          0.85641677     0.64683301     0.73701476           5486\n",
      "\u001b[38;5;16;48;5;231mO              0.99693113     0.99781921     0.99737497         754834\n",
      "\u001b[38;5;16;48;5;231m\n",
      "epoch 6 -[============================================================] 100.0% ...0.013761890740289388\n",
      "Cost after epoch 6: 0.013762\n",
      "General accurancy 0.9899168760357085 \n",
      "\n",
      "\u001b[38;5;15;48;5;232mTag            Precision      Recall         F1             Train tags     \n",
      "\u001b[38;5;16;48;5;217mB-art          0.50000000     0.07812500     0.13513514            338\n",
      "\u001b[38;5;16;48;5;217mB-eve          0.71428571     0.20000000     0.31250000            258\n",
      "\u001b[38;5;16;48;5;231mB-geo          0.84658173     0.84947785     0.84802732          32090\n",
      "\u001b[38;5;16;48;5;231mB-gpe          0.96175333     0.92479339     0.94291131          13450\n",
      "\u001b[38;5;16;48;5;217mB-nat          0.72727273     0.28571429     0.41025641            173\n",
      "\u001b[38;5;16;48;5;231mB-org          0.72429577     0.65467855     0.68772986          17001\n",
      "\u001b[38;5;16;48;5;231mB-per          0.82058047     0.75060338     0.78403361          14504\n",
      "\u001b[38;5;16;48;5;231mB-tim          0.90837065     0.86800527     0.88772934          17295\n",
      "\u001b[38;5;16;48;5;217mI-art          0.00000000     0.00000000     0.00000000            248\n",
      "\u001b[38;5;16;48;5;217mI-eve          0.36363636     0.09302326     0.14814815            210\n",
      "\u001b[38;5;16;48;5;231mI-geo          0.80146290     0.68238434     0.73714560           6290\n",
      "\u001b[38;5;16;48;5;217mI-gpe          1.00000000     0.41379310     0.58536585            169\n",
      "\u001b[38;5;16;48;5;217mI-nat          0.50000000     0.14285714     0.22222222             44\n",
      "\u001b[38;5;16;48;5;231mI-org          0.63510301     0.62422118     0.62961508          14216\n",
      "\u001b[38;5;16;48;5;231mI-per          0.83724632     0.81392650     0.82542173          14666\n",
      "\u001b[38;5;16;48;5;231mI-tim          0.82500000     0.66506718     0.73645058           5486\n",
      "\u001b[38;5;16;48;5;231mO              0.99730371     0.99717423     0.99723897         754834\n",
      "\u001b[38;5;16;48;5;231m\n",
      "epoch 7 -[============================================================] 100.0% ...0.012409647676870655\n",
      "Cost after epoch 7: 0.012410\n",
      "General accurancy 0.9900772438124766 \n",
      "\n",
      "\u001b[38;5;15;48;5;232mTag            Precision      Recall         F1             Train tags     \n",
      "\u001b[38;5;16;48;5;217mB-art          0.31578947     0.09375000     0.14457831            338\n",
      "\u001b[38;5;16;48;5;217mB-eve          0.55000000     0.22000000     0.31428571            258\n",
      "\u001b[38;5;16;48;5;231mB-geo          0.83501742     0.86298163     0.84876926          32090\n",
      "\u001b[38;5;16;48;5;231mB-gpe          0.96760259     0.92561983     0.94614572          13450\n",
      "\u001b[38;5;16;48;5;217mB-nat          0.41666667     0.35714286     0.38461538            173\n",
      "\u001b[38;5;16;48;5;231mB-org          0.73840445     0.63335455     0.68185712          17001\n",
      "\u001b[38;5;16;48;5;231mB-per          0.84163534     0.72043443     0.77633290          14504\n",
      "\u001b[38;5;16;48;5;231mB-tim          0.88715047     0.87722186     0.88215823          17295\n",
      "\u001b[38;5;16;48;5;217mI-art          0.00000000     0.00000000     0.00000000            248\n",
      "\u001b[38;5;16;48;5;217mI-eve          0.37500000     0.06976744     0.11764706            210\n",
      "\u001b[38;5;16;48;5;231mI-geo          0.77589641     0.69306050     0.73214286           6290\n",
      "\u001b[38;5;16;48;5;231mI-gpe          1.00000000     0.44827586     0.61904762            169\n",
      "\u001b[38;5;16;48;5;217mI-nat          0.28571429     0.28571429     0.28571429             44\n",
      "\u001b[38;5;16;48;5;231mI-org          0.68900425     0.56853583     0.62299979          14216\n",
      "\u001b[38;5;16;48;5;231mI-per          0.84979079     0.78568665     0.81648241          14666\n",
      "\u001b[38;5;16;48;5;231mI-tim          0.78929766     0.67946257     0.73027334           5486\n",
      "\u001b[38;5;16;48;5;231mO              0.99686318     0.99764657     0.99725473         754834\n",
      "\u001b[38;5;16;48;5;231m\n",
      "epoch 8 -[============================================================] 100.0% ...0.011236055350183953\n",
      "Cost after epoch 8: 0.011236\n",
      "General accurancy 0.9897511626663815 \n",
      "\n",
      "\u001b[38;5;15;48;5;232mTag            Precision      Recall         F1             Train tags     \n",
      "\u001b[38;5;16;48;5;217mB-art          0.40909091     0.14062500     0.20930233            338\n",
      "\u001b[38;5;16;48;5;217mB-eve          0.52173913     0.24000000     0.32876712            258\n",
      "\u001b[38;5;16;48;5;231mB-geo          0.82194582     0.86856320     0.84461175          32090\n",
      "\u001b[38;5;16;48;5;231mB-gpe          0.96296296     0.92396694     0.94306200          13450\n",
      "\u001b[38;5;16;48;5;217mB-nat          0.47368421     0.32142857     0.38297872            173\n",
      "\u001b[38;5;16;48;5;231mB-org          0.71739130     0.63017187     0.67095900          17001\n",
      "\u001b[38;5;16;48;5;231mB-per          0.80807213     0.75703942     0.78172378          14504\n",
      "\u001b[38;5;16;48;5;231mB-tim          0.88327236     0.87425938     0.87874276          17295\n",
      "\u001b[38;5;16;48;5;217mI-art          0.00000000     0.00000000     0.00000000            248\n",
      "\u001b[38;5;16;48;5;217mI-eve          0.21739130     0.11627907     0.15151515            210\n",
      "\u001b[38;5;16;48;5;231mI-geo          0.78775510     0.68683274     0.73384030           6290\n",
      "\u001b[38;5;16;48;5;231mI-gpe          0.92857143     0.44827586     0.60465116            169\n",
      "\u001b[38;5;16;48;5;217mI-nat          0.50000000     0.14285714     0.22222222             44\n",
      "\u001b[38;5;16;48;5;231mI-org          0.65930736     0.59306854     0.62443624          14216\n",
      "\u001b[38;5;16;48;5;231mI-per          0.82742317     0.81237911     0.81983213          14666\n",
      "\u001b[38;5;16;48;5;231mI-tim          0.77633008     0.68618042     0.72847682           5486\n",
      "\u001b[38;5;16;48;5;231mO              0.99731284     0.99698502     0.99714890         754834\n",
      "\u001b[38;5;16;48;5;231m\n",
      "epoch 9 -[============================================================] 100.0% ...0.010125413934785091\n",
      "Cost after epoch 9: 0.010125\n",
      "General accurancy 0.9900171058961886 \n",
      "\n",
      "\u001b[38;5;15;48;5;232mTag            Precision      Recall         F1             Train tags     \n",
      "\u001b[38;5;16;48;5;217mB-art          0.28000000     0.10937500     0.15730337            338\n",
      "\u001b[38;5;16;48;5;217mB-eve          0.44827586     0.26000000     0.32911392            258\n",
      "\u001b[38;5;16;48;5;231mB-geo          0.85679612     0.82625135     0.84124656          32090\n",
      "\u001b[38;5;16;48;5;231mB-gpe          0.95796178     0.93223140     0.94492147          13450\n",
      "\u001b[38;5;16;48;5;217mB-nat          0.34482759     0.35714286     0.35087719            173\n",
      "\u001b[38;5;16;48;5;231mB-org          0.73600000     0.61489497     0.67001907          17001\n",
      "\u001b[38;5;16;48;5;231mB-per          0.79752243     0.75100563     0.77356536          14504\n",
      "\u001b[38;5;16;48;5;231mB-tim          0.89945093     0.86273864     0.88071237          17295\n",
      "\u001b[38;5;16;48;5;217mI-art          0.00000000     0.00000000     0.00000000            248\n",
      "\u001b[38;5;16;48;5;217mI-eve          0.20833333     0.11627907     0.14925373            210\n",
      "\u001b[38;5;16;48;5;231mI-geo          0.82642777     0.65658363     0.73177987           6290\n",
      "\u001b[38;5;16;48;5;231mI-gpe          0.93333333     0.48275862     0.63636364            169\n",
      "\u001b[38;5;16;48;5;217mI-nat          0.50000000     0.14285714     0.22222222             44\n",
      "\u001b[38;5;16;48;5;231mI-org          0.71443299     0.53971963     0.61490683          14216\n",
      "\u001b[38;5;16;48;5;231mI-per          0.83554817     0.77833656     0.80592830          14666\n",
      "\u001b[38;5;16;48;5;231mI-tim          0.77454153     0.68905950     0.72930422           5486\n",
      "\u001b[38;5;16;48;5;231mO              0.99626522     0.99804434     0.99715398         754834\n",
      "\u001b[38;5;16;48;5;231m\n",
      "matplotlib wasnt found, plot was skipped\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAD8CAYAAACGsIhGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nk51CUgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ffa442389e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# finally train the model with given hyperparameters\n",
    "\n",
    "results = model.train(x_train, y_train, lr = 0.001, num_epoch = 10, plot = True, \n",
    "                      mb = 8, clip_value = None, epoch_bar = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Discussion\n",
    "##### As we see, the results are qiote good but still are not perfect. And the reseason is unbalanced problem. It's obvious we have low F1 rate on tags which have low amount of examples in train corpus. During evaluation the test corpus has them even less, qiote possible presented by unknown words, and that lead to low accurancy. There are few techniques which aimed to handle such problems and show state-of-the-art results like models with attention and/or comprehensive feature engineering or even CNN for NER tasks.\n",
    "##### For those who would like to experiment with or repeat the solution using GPU the tensorflow script is presented in the next cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes of train inputs x = (40766, 104), y = (40766, 104, 17)\n"
     ]
    }
   ],
   "source": [
    "x_train_tf = np.array(train_tokens_num_sents)\n",
    "y_train_indeces = np.array(train_tags_num_sents)\n",
    "y_train_tf = np.eye(u_tags.shape[0]).astype(np.uint8)[y_train_indeces]\n",
    "print('Shapes of train inputs x = {}, y = {}'.format(x_train_tf.shape, y_train_tf.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes of train inputs x = (7195, 104), y = (7195, 104)\n"
     ]
    }
   ],
   "source": [
    "x_test_tf = np.array(test_tokens_num_sents)\n",
    "y_test_indeces = np.array(test_tags_num_sents)\n",
    "y_test_tf = np.eye(u_tags.shape[0]).astype(np.uint8)[y_test_indeces]\n",
    "print('Shapes of train inputs x = {}, y = {}'.format(x_test_tf.shape, x_test_tf.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ivan/miniconda3/envs/env2_35/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "g = tf.Graph()\n",
    "\n",
    "sess = tf.InteractiveSession(graph=g)\n",
    "\n",
    "with g.as_default():\n",
    "  \n",
    "    with tf.device('/cpu:0'): # in case you are using GPU -  change \"c\" to \"g\"\n",
    "      \n",
    "        vocab_size = len(token2indices)\n",
    "        num_features = 1\n",
    "        num_outputs = len(tags2indices)\n",
    "\n",
    "        learning_rate = 0.001\n",
    "        num_epochs = 10\n",
    "        batch_size = 8\n",
    "\n",
    "        X = tf.placeholder(tf.float32, [None, None])\n",
    "        Y = tf.placeholder(tf.float32, [None, num_outputs])\n",
    "\n",
    "        embedding_size = 64\n",
    "        num_hidden_rnn = 32\n",
    "\n",
    "        shape = tf.shape(X)\n",
    "        word_ids = tf.cast(tf.reshape(X, [shape[0]*shape[1]]), tf.int32)\n",
    "\n",
    "        word_embeddings = tf.get_variable(\"Word_embeddings\", [vocab_size, embedding_size], \n",
    "                                          initializer = tf.contrib.layers.xavier_initializer(seed=1))\n",
    "\n",
    "        embedded_word_ids = tf.nn.embedding_lookup(word_embeddings, word_ids)\n",
    "\n",
    "        X_train = tf.reshape(embedded_word_ids, [shape[0], shape[1], embedding_size])\n",
    "\n",
    "        lstm_fw_cell = tf.nn.rnn_cell.BasicLSTMCell(num_units=num_hidden_rnn, activation = tf.nn.tanh)\n",
    "        lstm_bw_cell = tf.nn.rnn_cell.BasicLSTMCell(num_units=num_hidden_rnn, activation = tf.nn.tanh)\n",
    "\n",
    "        outputs_l1, _ = tf.nn.bidirectional_dynamic_rnn(lstm_fw_cell, lstm_bw_cell,\n",
    "                                                        X_train, dtype=tf.float32, scope='BLSTM_1') \n",
    "        rnn_outputs_l1 = tf.concat(outputs_l1, 2)\n",
    "    \n",
    "\n",
    "        shape2 = tf.shape(rnn_outputs_l1)\n",
    "\n",
    "        rnn_outputs_final = tf.reshape(rnn_outputs_l1, [shape2[0]*shape2[1], shape2[2]])\n",
    "\n",
    "        W = tf.get_variable(\"W\", [num_hidden_rnn*2, num_outputs], \n",
    "                            initializer = tf.contrib.layers.xavier_initializer(seed=1))\n",
    "        b = tf.get_variable('b', [1, num_outputs], \n",
    "                            initializer = tf.zeros_initializer())\n",
    "        Z = tf.add(tf.matmul(rnn_outputs_final, W), b)\n",
    "        AL = tf.nn.softmax(Z)\n",
    "\n",
    "        cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(\n",
    "               logits=Z, labels=Y))\n",
    "\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate = learning_rate, \n",
    "                                           beta1 = 0.9,\n",
    "                                           beta2 = 0.999,\n",
    "                                           epsilon = 1e-8,\n",
    "                                           use_locking = False)\n",
    "        train = optimizer.minimize(cost)\n",
    "\n",
    "    init = tf.global_variables_initializer()\n",
    "\n",
    "    costs = []\n",
    "\n",
    "    seed = 10\n",
    "\n",
    "    sh = y_test_tf.shape\n",
    "    _y_test = y_test_tf.reshape(sh[0]*sh[1], sh[2])\n",
    "\n",
    "    with tf.Session(config=config) as ses:  \n",
    "\n",
    "        ses.run(init)                    \n",
    "\n",
    "        for i in range(0, num_epochs):\n",
    "\n",
    "            epoch_cost = 0\n",
    "            seed += 1\n",
    "            minibatches_indeces = define_minibatches(x_train_tf.shape[0], batch_size, seed)\n",
    "\n",
    "            for i_mb, indeces in enumerate(minibatches_indeces):\n",
    "\n",
    "                mb_x = x_train_tf[indeces,:]\n",
    "                mb_y = np.copy(y_train_tf[indeces,:,:]).reshape(len(indeces)*maxlen, num_outputs)            \n",
    "                _, minibatch_cost = ses.run([train, cost], feed_dict={X: mb_x, Y: mb_y})\n",
    "\n",
    "                epoch_cost += minibatch_cost/len(minibatches_indeces)\n",
    "                progress(i_mb, len(minibatches_indeces), 'Current cost', np.around(epoch_cost, 5))\n",
    "            print('epoch is done')\n",
    "            if i % 1 == 0:\n",
    "\n",
    "                print()\n",
    "                print(\"Cost after epoch %i: %f\" %(i, epoch_cost))\n",
    "                \n",
    "                y_pred = ses.run(AL, feed_dict={X:x_test_tf})\n",
    "                _y_pred = np.around(y_pred)\n",
    "                \n",
    "                s = np.argmax(_y_pred[:,:], axis=1)\n",
    "                r = np.argmax(_y_test[:,:], axis=1)\n",
    "                \n",
    "                gacc = np.sum(r==s)/_y_test.shape[0]\n",
    "                print('General accurancy', gacc, '\\n')\n",
    "                \n",
    "                header = '{:15}{:15}{:15}{:15}{:15}'\n",
    "                print(header.format('Tag','Precision','Recall','F1','Tag Counts'))   \n",
    "                \n",
    "                line = '{:15}{:10.8f}{:15.8f}{:15.8f}{:15}' \n",
    "                precision = np.empty(num_outputs)\n",
    "                recall = np.empty(num_outputs)\n",
    "                f1 = np.empty(num_outputs)\n",
    "                accurancy = np.empty(num_outputs)\n",
    "                for num, name in indices2tags.items():\n",
    "                    selected = _y_pred[:,num]==1\n",
    "                    relevant = _y_test[:,num]==1\n",
    "                    tp = np.count_nonzero(selected*relevant)\n",
    "                    fp = np.count_nonzero(selected*(relevant-1))\n",
    "                    fn = np.count_nonzero((selected-1)*relevant)\n",
    "                    accurancy[num] = tp/np.count_nonzero(relevant)\n",
    "                    if accurancy[num] == 0:\n",
    "                        precision[num], recall[num], f1[num] = [0,0,0]\n",
    "                    else:\n",
    "                        precision[num] = (tp / (tp + fp))\n",
    "                        recall[num] = (tp / (tp + fn))\n",
    "                        f1[num] = 2*((precision[num] * recall[num])/(precision[num] + recall[num]))\n",
    "                    print(line.format(name, precision[num], recall[num], f1[num], train_tags_counts[name]))\n",
    "                print()\n",
    "                                                     \n",
    "            if i % 1 == 0:\n",
    "                costs.append(epoch_cost)\n",
    "\n",
    "        # plot the cost\n",
    "        plt.plot(np.squeeze(costs))\n",
    "        plt.ylabel('cost')\n",
    "        plt.xlabel('itexrations (per tens)')\n",
    "        plt.title(\"Learning rate =\" + str(learning_rate))\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
