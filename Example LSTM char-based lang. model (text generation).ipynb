{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p align=\"justify\">The next notebook shows an example script of building char-based language model and generate text with LSTM recurrent network implemented from scratch with numpy only. The idea of the script was taken from KERAS tutorial here:</p>\n",
    "<a>https://github.com/keras-team/keras/blob/master/examples/lstm_text_generation.py</a> \n",
    "<p align=\"justify\">and script basically repeats all steps (and some code) from tutorial except the imlementation of neural network itself. The implementation was made purely for my educational purposes, could be useful for someone with the same purposes and obviously is not as efficient as any of the popular libraries or frameworks like Keras or Tensorflow. However, it can give a deeper :) understanding and hands-on experience with the neural network architectures.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Language model as a corpus we can choose any text (book or set of books). For this case I've chosen\n",
    "# \"The War of the Worlds\" by H. G. Wells. http://www.gutenberg.org/ebooks/36\n",
    "\n",
    "with open(\"testdata/The War of the Worlds.txt\", encoding='utf-8') as f:\n",
    "    examples = f.read().lower()\n",
    "\n",
    "examples_len = len(examples)\n",
    "print('corpus length (number of chars):', examples_len)\n",
    "\n",
    "chars = sorted(list(set(examples)))\n",
    "len_chars = len(chars)\n",
    "print('total chars:', len_chars) #get unique chars\n",
    "\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars)) #build dictionaries mapping unique chars to indeces\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))\n",
    "\n",
    "# cut the text in semi-redundant sequences of maxlen characters - like in Keras tutorial\n",
    "maxlen = 40\n",
    "step = 3\n",
    "\n",
    "examples = np.array(list(examples))\n",
    "examples_num = np.zeros(examples.shape)\n",
    "\n",
    "# convert chars into indeces\n",
    "for k,v in char_indices.items():\n",
    "    examples_num[np.where(examples == k)] = v\n",
    "examples_num = examples_num.astype(np.int)\n",
    "\n",
    "# build index tables for our sequances \n",
    "x_index_table = np.arange(maxlen)+np.arange(0, len(examples)-maxlen, step).reshape(-1,1)\n",
    "# As we are going to predict the next char for given sequance of chars, the labels for sequances are just next\n",
    "# chars (+1 index)\n",
    "y_index_table = x_index_table+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m = x_index_table.shape[0]\n"
    "# Then simply select data from examples\n",
    "x_indeces = examples_num[x_index_table].T.astype(np.uint16)\n",
    "y_indeces = examples_num[y_index_table].T.astype(np.uint16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally represent indeces as one-hot vectors and reshape into required shape:\n",
    "# (number of features, batch size, sequance length)\n",
    "x_train = np.eye(len_chars).astype(np.uint8)[x_indeces].T\n",
    "y_train = np.eye(len_chars).astype(np.uint8)[y_indeces].T\n",
    "print('Shapes of train inputs x = {}, y = {}'.format(x_train.shape, y_train.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Sampling functions on epoch during learning are taken and adopted from Keras-team example script\n",
    "def sample(preds, temperature=1.0):\n",
    "    \n",
    "    # helper function to sample an index from a probability array resulted from model\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1,preds,1)\n",
    "    return np.argmax(probas)\n",
    "\n",
    "\n",
    "def on_epoch_end(*args):\n",
    "    \n",
    "    # Function invoked at end of each epoch. Prints generated text (here - names of dinos).\n",
    "    if args[1] % 5 == 0: # Lets check results every 5 epochs\n",
    "        print('----- Generating text after Epoch: %d' % args[1])\n",
    "        print('----- Cost after epoch %i: %f' %(args[1]+1, args[2]))\n",
    "        end_char = char_indices[' ']\n",
    "        chars_len = len(chars)\n",
    "        for diversity in [0.2, 0.5, 1.0, 1.2]:\n",
    "            initial_sample_index = np.random.choice(np.arange(m))\n",
    "            print('----- diversity:', diversity)\n",
    "            init_text = ''.join([indices_char[c] for c in \n",
    "                                 np.argmax(x_train[:,initial_sample_index,:], axis=0)])\n",
    "            print('----- Generating with seed: \\n\"' + init_text + '\".....\\n')\n",
    "            generated = ''\n",
    "            generated += init_text\n",
    "            next_index = initial_sample_index\n",
    "            while True: \n",
    "                if next_index == end_char and len(generated) > 200:\n",
    "                    break\n",
    "                else:\n",
    "                    x_pred = np.zeros((len(chars), 1, len(generated)))\n",
    "                    for t, char in enumerate(generated):\n",
    "                        x_pred[char_indices[char], 0, t] = 1\n",
    "                    A = args[0].predict(x_pred)\n",
    "                    next_index = sample(A[:,:,-1].ravel(), diversity)\n",
    "                    next_char = indices_char[next_index]\n",
    "                    generated += next_char\n",
    "            print(generated,'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model train\n",
    "\n",
    "In fact here I just import implemented tools and show how to use them. check mylab dir for details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import required tools for tet generation model\n",
    "\n",
    "from mylab import nnet\n",
    "from mylab.layers import layer, lstm_layer\n",
    "from mylab.utils import tanh, softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nnet() # create the instance of the model\n",
    "\n",
    "model.add(lstm_layer(128)) # add LSTM layer, hidden units = 128 (activation function is tanh by default)\n",
    "model.add(layer(len(char_indices), softmax)) # add simple layer for softmax predictions. \n",
    "                                             # hidden unit = unique chars (amount of our classes)\n",
    "                                             # activation function - softmax\n",
    "\n",
    "model.report_function = on_epoch_end # add report function we specified before \n",
    "\n",
    "# finally train the model with given hyperparameters\n",
    "# According to Keras tutorial it should take up to 60 epochs, for this implementation should be the same \n",
    "# or even more. \n",
    "results = model.train(x_train, y_train, lr = 0.01, num_epoch = 60, plot = True, \n",
    "                      mb = 64, clip_value = 5, epoch_bar = True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
